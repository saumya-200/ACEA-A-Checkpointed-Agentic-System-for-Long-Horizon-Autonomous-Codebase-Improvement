# ğŸš€ ACEA Sentinel

**Autonomous Codebase Enhancement Agent** - An AI-powered autonomous software development platform that designs, generates, tests, and self-heals code.

![ACEA Banner](docs/banner.png)

## âœ¨ Features

- **ğŸ—ï¸ Architect Agent** - Designs system architecture from natural language prompts
- **ğŸ’» Virtuoso Agent** - Generates production-ready code in batches  
- **ğŸ›¡ï¸ Sentinel Agent** - Scans for security vulnerabilities
- **ğŸ‘ï¸ Watcher Agent** - Validates generated code and triggers self-healing
- **ğŸ”„ Self-Healing Loop** - Automatically fixes errors and regenerates code
- **â˜ï¸ + ğŸ  Hybrid AI** - Uses Gemini API with automatic Ollama local model fallback

## ğŸ–¥ï¸ System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **GPU** | 8GB VRAM | 12GB+ VRAM (RTX 3060+) |
| **RAM** | 16GB | 32GB |
| **CPU** | 8 cores | 16+ cores |
| **Storage** | 20GB free | 50GB free |

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/saumya-200/ACEA-A-Checkpointed-Agentic-System-for-Long-Horizon-Autonomous-Codebase-Improvement.git
cd ACEA-A-Checkpointed-Agentic-System-for-Long-Horizon-Autonomous-Codebase-Improvement
```

### 2. Backend Setup

```bash
cd backend
python -m venv venv

# Windows
.\venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
cd frontend
npm install
```

### 4. Environment Configuration

Create `backend/.env` file:

```env
# Gemini API Keys (get from https://aistudio.google.com/apikey)
GEMINI_API_KEYS="your_api_key_1,your_api_key_2"

# Database
DATABASE_URL=sqlite:///./acea.db

# Security
JWT_SECRET="your-secret-key-here"
ACCESS_TOKEN_EXPIRE_MINUTES=30
```

### 5. (Optional) Local Model Setup with Ollama

For unlimited local inference when API quotas are exhausted:

```bash
# Install Ollama
winget install Ollama.Ollama  # Windows
# or download from https://ollama.com/download

# Start Ollama server
ollama serve

# Pull the coding model (~9GB)
ollama pull qwen2.5-coder:14b
```

## ğŸš€ Running the Application

### Start Backend Server

```bash
cd backend
python run_backend.py
```

Backend will be available at: `http://localhost:8000`

### Start Frontend Development Server

```bash
cd frontend
npm run dev
```

Frontend will be available at: `http://localhost:3000`

## ğŸ® Usage

1. Open `http://localhost:3000` in your browser
2. Navigate to the **War Room** dashboard
3. Enter a prompt like: *"Create a tic-tac-toe game"*
4. Watch the agents work in real-time!

### Example Prompts

- "Make a simple todo app with task management"
- "Create a weather dashboard with API integration"
- "Build an e-commerce product page with cart functionality"

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ACEA SENTINEL CORE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   User Prompt                                                   â”‚
â”‚        â†“                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚Architect â”‚â”€â”€â”€â–¶â”‚Virtuoso  â”‚â”€â”€â”€â–¶â”‚Sentinel  â”‚â”€â”€â”€â–¶â”‚ Watcher  â”‚ â”‚
â”‚   â”‚(Design)  â”‚    â”‚(Generate)â”‚    â”‚(Security)â”‚    â”‚(Verify)  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                        â–²                               â”‚        â”‚
â”‚                        â”‚         Self-Healing          â”‚        â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                 Hybrid Model Client                      â”‚  â”‚
â”‚   â”‚   Gemini API (Primary) â”€â”€â–¶ Ollama Local (Fallback)      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
ACEA/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/           # AI Agents
â”‚   â”‚   â”‚   â”œâ”€â”€ architect.py  # System design
â”‚   â”‚   â”‚   â”œâ”€â”€ virtuoso.py   # Code generation
â”‚   â”‚   â”‚   â”œâ”€â”€ sentinel.py   # Security scanning
â”‚   â”‚   â”‚   â”œâ”€â”€ watcher.py    # Visual verification
â”‚   â”‚   â”‚   â””â”€â”€ state.py      # Agent state management
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py     # Configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ key_manager.py# API key rotation
â”‚   â”‚   â”‚   â”œâ”€â”€ local_model.py# Ollama integration
â”‚   â”‚   â”‚   â””â”€â”€ socket_manager.py
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ endpoints.py  # REST API routes
â”‚   â”œâ”€â”€ orchestrator.py       # LangGraph workflow
â”‚   â””â”€â”€ main.py               # FastAPI entry point
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ page.tsx      # Landing page
â”‚   â”‚       â””â”€â”€ war-room/
â”‚   â”‚           â””â”€â”€ page.tsx  # Main dashboard
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ Configuration Options

### API Key Rotation

Add multiple API keys for automatic rotation on rate limits:

```env
GEMINI_API_KEYS="key1,key2,key3,key4,key5"
```

### Local Model Options

| Model | VRAM | Quality | Command |
|-------|------|---------|---------|
| qwen2.5-coder:14b | 10GB | â­â­â­â­â­ | `ollama pull qwen2.5-coder:14b` |
| qwen2.5-coder:7b | 6GB | â­â­â­â­ | `ollama pull qwen2.5-coder:7b` |
| codellama:13b | 8GB | â­â­â­ | `ollama pull codellama:13b` |

## ğŸ› ï¸ Tech Stack

**Backend:**
- Python 3.12
- FastAPI
- LangGraph
- Google Generative AI SDK
- Ollama (Local Models)
- Socket.IO

**Frontend:**
- Next.js 15
- React
- Tailwind CSS 4
- TypeScript
- Lucide Icons

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

